#!/usr/bin/env python3
"""
BBIC Content Agent:
- Reads latest curated trends (YouTube) and Reddit intake
- Opens "Daily show outline" + "3 Shorts" issues for P5 (BBIC)
- Requires GH_TOKEN and GITHUB_REPO env vars
"""
import os, json, glob, datetime as dt
import requests

P5_LABELS = ["Project:P5-BBIC", "Dept:Content", "Horizon:Now", "Status:Todo", "Priority:Normal"]

def gh_create_issue(repo: str, title: str, body: str, labels: list[str]):
    token = os.environ.get("GH_TOKEN") or os.environ.get("GITHUB_TOKEN")
    if not token:
        raise RuntimeError("Missing GH_TOKEN/GITHUB_TOKEN")
    url = f"https://api.github.com/repos/{repo}/issues"
    resp = requests.post(url, json={"title": title, "body": body, "labels": labels},
                         headers={"Authorization": f"Bearer {token}",
                                  "Accept":"application/vnd.github+json"})
    if not (200 <= resp.status_code < 300):
        raise RuntimeError(f"GitHub issue create failed: {resp.status_code} {resp.text}")
    return resp.json()["html_url"]

def latest(path_glob: str) -> str | None:
    files = sorted(glob.glob(path_glob))
    return files[-1] if files else None

def main():
    repo = os.environ.get("GITHUB_REPO")
    if not repo:
        raise RuntimeError("Set GITHUB_REPO=YOURUSER/resonance-uy-py")

    root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
    curated_dir = os.path.join(root, "data", "bbic", "curated")
    yt_latest = latest(os.path.join(curated_dir, "trends_*.json"))

    # Optional Reddit
    reddit_dir = os.path.join(root, "data", "bbic", "reddit")
    rd_latest = latest(os.path.join(reddit_dir, "reddit_*.jsonl"))

    day = dt.datetime.utcnow().strftime("%Y-%m-%d")
    title = f"BBIC: Daily Show Outline — {day}"
    section = []

    if yt_latest and os.path.exists(yt_latest):
        cur = json.load(open(yt_latest))
        items = cur.get("items", [])[:6]
        bullets = "\n".join([f"- [{i['title']}]({i['url']}) — {i.get('view_count','?')} views" for i in items])
        section.append(f"### YouTube trend picks\n{bullets}")

    if rd_latest and os.path.exists(rd_latest):
        lines = [json.loads(l) for l in open(rd_latest, encoding="utf-8").read().splitlines()]
        lines = sorted(lines, key=lambda x: x.get("score",0), reverse=True)[:5]
        bullets = "\n".join([f"- [{x['title']}]({x['url']}) (r/{x['subreddit']}, {x['score']} pts)" for x in lines])
        section.append(f"### Reddit signals\n{bullets}")

    body = "\n\n".join([
        "> Auto-generated by BBIC Content Agent",
        *section,
        "### Segment plan\n- Cold open (30–45s)\n- 5 Headlines (90s)\n- Deep dive (4–6 min)\n- Calls to action",
        "### Shorts to cut\n- [ ] Short #1\n- [ ] Short #2\n- [ ] Short #3"
    ])

    url = gh_create_issue(repo, title, body, P5_LABELS)
    print(f"[bbic] Created Daily Show issue → {url}")

    # Also create Shorts checklist as a second issue (optional)
    shorts_url = gh_create_issue(repo, f"BBIC: Shorts (3) — {day}",
                                 "Auto-generated.\n- [ ] Short idea 1\n- [ ] Short idea 2\n- [ ] Short idea 3",
                                 P5_LABELS)
    print(f"[bbic] Created Shorts issue → {shorts_url}")

if __name__ == "__main__":
    main()